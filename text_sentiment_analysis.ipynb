{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa57e27-96d2-4d51-ac61-20313b159cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def load_multiple_excel_files(folder_path):\n",
    "    \"\"\"\n",
    "    Load multiple Excel files from a folder into a dictionary of DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing Excel files.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are file names and values are DataFrames.\n",
    "    \"\"\"\n",
    "    # Find all Excel files in the folder\n",
    "    excel_files = glob.glob(f\"{folder_path}/*.xlsx\")  # Adjust to \"*.xls\" if needed\n",
    "    \n",
    "    # Initialize a dictionary to store DataFrames\n",
    "    dataframes = {}\n",
    "    \n",
    "    for file in excel_files:\n",
    "        # Extract file name without extension\n",
    "        file_name = file.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        # Load the Excel file into a DataFrame\n",
    "        dataframes[file_name] = pd.read_excel(file)\n",
    "    \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a9fefe2-ed07-49fe-8c4f-14dd17188ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: vader redo\\absa_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-20                                  Absa? Never again\n",
      "1 2024-11-18  @AbsaGhana I want a loan to go and write my En...\n",
      "2 2024-11-18  @AbsaGhana JobCenterGH offers a fast and effic...\n",
      "3 2024-11-17  @AbsaGhana $AMB price dropped but $SWINE Buys ...\n",
      "4 2024-11-16  @AbsaGhana Imitating Access Bank method! Great...\n",
      "File: vader redo\\access_bank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-19  Can you people send give me my money ? @moneyg...\n",
      "1 2024-11-19            I bought 21gh airtime, hasnâ€™t reflected\n",
      "2 2024-11-18  Reporting a fraudster who is deceiving people ...\n",
      "3 2024-11-15   @AccessBankGhana , Iâ€™ve spent close to 2 hour...\n",
      "4 2024-11-12   @AccessBankGhana please can you work on my na...\n",
      "File: vader redo\\adb_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-19   @adb_Ghana l have still not received a transa...\n",
      "1 2024-11-10                                            Awesome\n",
      "2 2024-11-04                         Nothing \"effortless\" here.\n",
      "3 2024-11-02                                           Good job\n",
      "File: vader redo\\calbank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-20   @CalBankPLC please can I get a personal loan ...\n",
      "1 2024-11-20   @CalBankPLC I've been trying to call your cus...\n",
      "2 2024-11-20                                ðŸ˜‚ðŸ˜­Switch to calbank\n",
      "3 2024-11-19   @CalBankPLC consistently sending a transactio...\n",
      "4 2024-11-19   @CalBankPLC has the worst customers service e...\n",
      "File: vader redo\\cbg_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-18  I tagged you but you intentionally ignored my ...\n",
      "1 2024-11-18  Stop what you are doing here, it's needless an...\n",
      "2 2024-11-14                                Is our money safe ðŸ«£\n",
      "3 2024-11-13   @CBGBankLtd does it affect the ability to rec...\n",
      "4 2024-11-11                                       Impressive ðŸ«¡\n",
      "File: vader redo\\ecobank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-20  Dear  @EcobankGhanaPLC your services at Mile 7...\n",
      "1 2024-11-18  you guys need to fix your Customer Care servic...\n",
      "2 2024-11-18  headoffice branch has loads of teller booths w...\n",
      "3 2024-11-15   Ecobank, an absolute mess. Bad service, horri...\n",
      "4 2024-11-13  The EDC I wonâ€™t do again. Give me my money, yo...\n",
      "File: vader redo\\fidelity_bank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-20  Thatâ€™s a nice way to treat a platinum card mem...\n",
      "1 2024-11-20  You people should at least employ sensible peo...\n",
      "2 2024-11-20   @fidelitybankplc i recharged airtime from my ...\n",
      "3 2024-11-19  Please your adum Pz workers they should try an...\n",
      "4 2024-11-19  I am giving you guys one week to reinstate my ...\n",
      "File: vader redo\\first_atlantic_bank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-16  Loading my wallet....I love your digital platf...\n",
      "1 2024-11-13  Thanks for your feedback. I will visit any of ...\n",
      "2 2024-11-13  Refreshingly different indeed my best choice o...\n",
      "3 2024-11-13        Ihv not regret joining the purple family ðŸ’œðŸ’œ\n",
      "4 2024-11-11   @FirstAtlanticGH How long does it take to cre...\n",
      "File: vader redo\\gcb_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-19  Which number do I call for my issue to be solv...\n",
      "1 2024-11-14  I would love and appreciate the integration of...\n",
      "2 2024-11-13  will I continue receiving these numerous SMS m...\n",
      "3 2024-11-09   you've been investigating my failed ATM trans...\n",
      "4 2024-11-12  Excellent work Thanks for observing Internatio...\n",
      "File: vader redo\\gtbank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-18  I tried using my GT bank master card and they ...\n",
      "1 2024-11-18  Hi @GTBankGhana with your DM closed how do we ...\n",
      "2 2024-11-18  Hello I canâ€™t send a direct message on here. I...\n",
      "3 2024-11-18  I have done an application getting to more tha...\n",
      "4 2024-11-18            How long does it take after application\n",
      "File: vader redo\\stanbic_bank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-19  In everything you do, avoid banking with \\n@St...\n",
      "1        NaT  Can I create an account with you guys without ...\n",
      "2        NaT  fix your self. How does it take over 2 hours t...\n",
      "3 2024-11-17    Never Ever Will I Invest At Stanbic Banks Again\n",
      "4 2024-11-16  its been very hard trying to reach your call c...\n",
      "File: vader redo\\standard_chartered_bank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-13  My brother in America wants to create a person...\n",
      "1 2024-11-08  Iâ€™ve sent 4 follow-up multiple emails concerni...\n",
      "2 2024-11-07  love your services but i canâ€™t never hear the ...\n",
      "3 2024-11-06             why is the banking app so complicated?\n",
      "4 2024-11-01  to be honest your customer service is the wors...\n",
      "File: vader redo\\uba_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-14                           UBA Bank be correct pass\n",
      "1 2024-11-14  Uba please help me My account was debited 3 ti...\n",
      "2 2024-11-11  I already have UBA account but I want to downl...\n",
      "3 2024-11-11  After leaving over GHâ‚µ200K unattended in my sa...\n",
      "File: vader redo\\zenith_bank_sentiments\n",
      "        date                                               post\n",
      "0 2024-11-18  Please fix your 24hr Zenith Direct Call Center...\n",
      "1 2024-11-14  I need my funds and won't and not interested i...\n",
      "2 2024-11-08  Hello, your Abelemkpe ATM debited an amount fr...\n",
      "3 2024-11-12  I sent money via the I sent money via the  @Ze...\n",
      "4 2024-11-13  Simple instant transfer and itâ€™s been an hour ...\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"File path\"# Replace with the folder containing your Excel files\n",
    "loaded_dataframes = load_multiple_excel_files(folder_path)\n",
    "\n",
    "# Access the DataFrames\n",
    "for file_name, df in loaded_dataframes.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(df.head())  # Display the first few rows of each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a81521d-fbc1-4f15-823d-b82c2568197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (2.14.0)\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.1.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "   ---------------------------------------- 0.0/289.9 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 174.1/289.9 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 289.9/289.9 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading pyahocorasick-2.1.0-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f39fb2b-c2f6-4798-89d8-acc8dda5b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from emoji import demojize\n",
    "import contractions\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_multiple_dataframes(dataframes, column_name):\n",
    "    \"\"\"\n",
    "    Preprocess a specified text column in a dictionary of DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframes (dict): A dictionary of DataFrames (e.g., loaded from Excel sheets).\n",
    "        column_name (str): The name of the text column to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are the same as the input, and values are DataFrames \n",
    "              with an additional 'cleaned_<column_name>' column.\n",
    "    \"\"\"\n",
    "    # Initialize a lemmatizer and stop words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def preprocess_text(text):\n",
    "        \"\"\"\n",
    "        Preprocess a single text entry by cleaning, tokenizing, removing stopwords, and lemmatizing.\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "        \n",
    "        \n",
    "        # Normalize text\n",
    "        text = text.lower()\n",
    "        text = contractions.fix(text)\n",
    "\n",
    "        # Remove URLs and email addresses\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "        # Handle emojis\n",
    "        text = demojize(text)\n",
    "    \n",
    "        # Remove special characters (retain punctuation and emojis)\n",
    "        text = re.sub(r'[^A-Za-z0-9\\s\\!\\?\\.,:]', '', text)\n",
    "    \n",
    "        # Reduce repeated characters\n",
    "        text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "        \n",
    "        # Remove mentions, hashtags, URLs, and special characters\n",
    "        text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "        text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "        \n",
    "\n",
    "        # Step 2: Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Step 3: Remove stopwords\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # Step 4: Lemmatization\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        # Join tokens back into a single string\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    # Process each DataFrame in the dictionary\n",
    "    processed_dataframes = {}\n",
    "    for key, df in dataframes.items():\n",
    "        # Ensure the column exists in the DataFrame\n",
    "        if column_name not in df.columns:\n",
    "            raise ValueError(f\"Column '{column_name}' not found in DataFrame '{key}'.\")\n",
    "        \n",
    "        # Make a copy of the DataFrame to avoid modifying the original\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Apply preprocessing to the specified column\n",
    "        df_copy[f'cleaned_{column_name}'] = df_copy[column_name].apply(preprocess_text)\n",
    "        \n",
    "        # Store the processed DataFrame in the dictionary\n",
    "        processed_dataframes[key] = df_copy\n",
    "    \n",
    "    return processed_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d8738d8-cd10-42ea-a9ba-749b0dd03ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dfs = preprocess_multiple_dataframes(loaded_dataframes, 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5006534-d152-43cb-9b78-8f84063e0af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: vader redo\\absa_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-20                                  Absa? Never again   \n",
      "1 2024-11-18  @AbsaGhana I want a loan to go and write my En...   \n",
      "2 2024-11-18  @AbsaGhana JobCenterGH offers a fast and effic...   \n",
      "3 2024-11-17  @AbsaGhana $AMB price dropped but $SWINE Buys ...   \n",
      "4 2024-11-16  @AbsaGhana Imitating Access Bank method! Great...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0                                       absa ? never  \n",
      "1  absaghana want loan go write energy commission...  \n",
      "2  absaghana jobcentergh offer fast efficient hir...  \n",
      "3  absaghana amb price dropped swine buy keep com...  \n",
      "4  absaghana imitating access bank method ! great...  \n",
      "Sheet: vader redo\\access_bank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-19  Can you people send give me my money ? @moneyg...   \n",
      "1 2024-11-19            I bought 21gh airtime, hasnâ€™t reflected   \n",
      "2 2024-11-18  Reporting a fraudster who is deceiving people ...   \n",
      "3 2024-11-15   @AccessBankGhana , Iâ€™ve spent close to 2 hour...   \n",
      "4 2024-11-12   @AccessBankGhana please can you work on my na...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  people send give money ? moneygram made sent m...  \n",
      "1                    bought 21gh airtime , reflected  \n",
      "2  reporting fraudster deceiving people job recru...  \n",
      "3  accessbankghana , spent close 2 hour new town ...  \n",
      "4            accessbankghana please work name change  \n",
      "Sheet: vader redo\\adb_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-19   @adb_Ghana l have still not received a transa...   \n",
      "1 2024-11-10                                            Awesome   \n",
      "2 2024-11-04                         Nothing \"effortless\" here.   \n",
      "3 2024-11-02                                           Good job   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  adbghana l still received transaction receipt ...  \n",
      "1                                            awesome  \n",
      "2                               nothing effortless .  \n",
      "3                                           good job  \n",
      "Sheet: vader redo\\calbank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-20   @CalBankPLC please can I get a personal loan ...   \n",
      "1 2024-11-20   @CalBankPLC I've been trying to call your cus...   \n",
      "2 2024-11-20                                ðŸ˜‚ðŸ˜­Switch to calbank   \n",
      "3 2024-11-19   @CalBankPLC consistently sending a transactio...   \n",
      "4 2024-11-19   @CalBankPLC has the worst customers service e...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  calbankplc please get personal loan get office...  \n",
      "1  calbankplc trying call customer service since ...  \n",
      "2  : facewithtearsofjoy : :loudlycryingface : swi...  \n",
      "3  calbankplc consistently sending transaction tw...  \n",
      "4  calbankplc worst customer service ever . trust...  \n",
      "Sheet: vader redo\\cbg_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-18  I tagged you but you intentionally ignored my ...   \n",
      "1 2024-11-18  Stop what you are doing here, it's needless an...   \n",
      "2 2024-11-14                                Is our money safe ðŸ«£   \n",
      "3 2024-11-13   @CBGBankLtd does it affect the ability to rec...   \n",
      "4 2024-11-11                                       Impressive ðŸ«¡   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0         tagged intentionally ignored message , vim  \n",
      "1  stop , needle needful .. provide ezwitch card ...  \n",
      "2                  money safe : facewithpeekingeye :  \n",
      "3  cbgbankltd affect ability receive fund bank ac...  \n",
      "4                        impressive : salutingface :  \n",
      "Sheet: vader redo\\ecobank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-20  Dear  @EcobankGhanaPLC your services at Mile 7...   \n",
      "1 2024-11-18  you guys need to fix your Customer Care servic...   \n",
      "2 2024-11-18  headoffice branch has loads of teller booths w...   \n",
      "3 2024-11-15   Ecobank, an absolute mess. Bad service, horri...   \n",
      "4 2024-11-13  The EDC I wonâ€™t do again. Give me my money, yo...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  dear ecobankghanaplc service mile 7 branch slo...  \n",
      "1  guy need fix customer care service . connectin...  \n",
      "2  headoffice branch load teller booth eticketing...  \n",
      "3  ecobank , absolute mess . bad service , horrib...  \n",
      "4  edc . give money , telling done paying 2023 re...  \n",
      "Sheet: vader redo\\fidelity_bank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-20  Thatâ€™s a nice way to treat a platinum card mem...   \n",
      "1 2024-11-20  You people should at least employ sensible peo...   \n",
      "2 2024-11-20   @fidelitybankplc i recharged airtime from my ...   \n",
      "3 2024-11-19  Please your adum Pz workers they should try an...   \n",
      "4 2024-11-19  I am giving you guys one week to reinstate my ...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  nice way treat platinum card member , done stu...  \n",
      "1  people least employ sensible people answer cos...  \n",
      "2  fidelitybankplc recharged airtime fidelity ban...  \n",
      "3  please adum pz worker try respect queue.this m...  \n",
      "4  giving guy one week reinstate money . closing ...  \n",
      "Sheet: vader redo\\first_atlantic_bank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-16  Loading my wallet....I love your digital platf...   \n",
      "1 2024-11-13  Thanks for your feedback. I will visit any of ...   \n",
      "2 2024-11-13  Refreshingly different indeed my best choice o...   \n",
      "3 2024-11-13        Ihv not regret joining the purple family ðŸ’œðŸ’œ   \n",
      "4 2024-11-11   @FirstAtlanticGH How long does it take to cre...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  loading wallet .. love digital platform : smil...  \n",
      "1  thanks feedback . visit branch get one soon po...  \n",
      "2  refreshingly different indeed best choice open...  \n",
      "3  ihv regret joining purple family : purpleheart...  \n",
      "4  firstatlanticgh long take credit account inflo...  \n",
      "Sheet: vader redo\\gcb_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-19  Which number do I call for my issue to be solv...   \n",
      "1 2024-11-14  I would love and appreciate the integration of...   \n",
      "2 2024-11-13  will I continue receiving these numerous SMS m...   \n",
      "3 2024-11-09   you've been investigating my failed ATM trans...   \n",
      "4 2024-11-12  Excellent work Thanks for observing Internatio...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  number call issue solved apparently hotline st...  \n",
      "1  would love appreciate integration internationa...  \n",
      "2  continue receiving numerous sm message mainten...  \n",
      "3  investigating failed atm transaction 4 month ....  \n",
      "4  excellent work thanks observing international ...  \n",
      "Sheet: vader redo\\gtbank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-18  I tried using my GT bank master card and they ...   \n",
      "1 2024-11-18  Hi @GTBankGhana with your DM closed how do we ...   \n",
      "2 2024-11-18  Hello I canâ€™t send a direct message on here. I...   \n",
      "3 2024-11-18  I have done an application getting to more tha...   \n",
      "4 2024-11-18            How long does it take after application   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  tried using gt bank master card said invalid t...  \n",
      "1  hi gtbankghana dm closed contact make inquiry ...  \n",
      "2  hello send direct message . called customer se...  \n",
      "3  done application getting week . relationship o...  \n",
      "4                              long take application  \n",
      "Sheet: vader redo\\stanbic_bank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-19  In everything you do, avoid banking with \\n@St...   \n",
      "1        NaT  Can I create an account with you guys without ...   \n",
      "2        NaT  fix your self. How does it take over 2 hours t...   \n",
      "3 2024-11-17    Never Ever Will I Invest At Stanbic Banks Again   \n",
      "4 2024-11-16  its been very hard trying to reach your call c...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  everything , avoid banking stanbicbankgh . ass...  \n",
      "1  create account guy without physically going ba...  \n",
      "2  fix self . take 2 hour tell someone go east le...  \n",
      "3                     never ever invest stanbic bank  \n",
      "4  hard trying reach call center morning . way re...  \n",
      "Sheet: vader redo\\standard_chartered_bank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-13  My brother in America wants to create a person...   \n",
      "1 2024-11-08  Iâ€™ve sent 4 follow-up multiple emails concerni...   \n",
      "2 2024-11-07  love your services but i canâ€™t never hear the ...   \n",
      "3 2024-11-06             why is the banking app so complicated?   \n",
      "4 2024-11-01  to be honest your customer service is the wors...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  brother america want create personal bank acco...  \n",
      "1  sent 4 followup multiple email concerning debi...  \n",
      "2  love service never hear indian speaking custom...  \n",
      "3                          banking app complicated ?  \n",
      "4  honest customer service worst ever experienced...  \n",
      "Sheet: vader redo\\uba_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-14                           UBA Bank be correct pass   \n",
      "1 2024-11-14  Uba please help me My account was debited 3 ti...   \n",
      "2 2024-11-11  I already have UBA account but I want to downl...   \n",
      "3 2024-11-11  After leaving over GHâ‚µ200K unattended in my sa...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0                               uba bank correct pas  \n",
      "1  uba please help account debited 3 time unknown...  \n",
      "2  already uba account want download app use , po...  \n",
      "3  leaving gh200k unattended saving account 6 mon...  \n",
      "Sheet: vader redo\\zenith_bank_sentiments\n",
      "        date                                               post  \\\n",
      "0 2024-11-18  Please fix your 24hr Zenith Direct Call Center...   \n",
      "1 2024-11-14  I need my funds and won't and not interested i...   \n",
      "2 2024-11-08  Hello, your Abelemkpe ATM debited an amount fr...   \n",
      "3 2024-11-12  I sent money via the I sent money via the  @Ze...   \n",
      "4 2024-11-13  Simple instant transfer and itâ€™s been an hour ...   \n",
      "\n",
      "                                        cleaned_post  \n",
      "0  please fix 24hr zenith direct call center . 3h...  \n",
      "1    need fund interested banking .. poor service ..  \n",
      "2  hello , abelemkpe atm debited amount account w...  \n",
      "3  sent money via sent money via zenithbankghapp ...  \n",
      "4             simple instant transfer hour reflected  \n"
     ]
    }
   ],
   "source": [
    "for sheet_name, df in processed_dfs.items():\n",
    "    print(f\"Sheet: {sheet_name}\")\n",
    "    print(df.head())  # Display the first few rows of the processed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7e10e1c-d456-4980-9a17-5fe649ab4a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4591c61-d506-49e3-a5ef-89ef12894634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a4098e-d4b8-4e31-ae44-ecccabb9a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def vader_sentiment_analysis(dataframes, text_column):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis using VADER on the specified column of multiple DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "        dataframes (dict): A dictionary of DataFrames.\n",
    "        text_column (str): The name of the column containing cleaned text.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of DataFrames with additional sentiment score columns.\n",
    "    \"\"\"\n",
    "    # Initialize VADER sentiment analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    processed_dataframes = {}\n",
    "\n",
    "    for key, df in dataframes.items():\n",
    "        # Ensure the column exists\n",
    "        if text_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{text_column}' not found in DataFrame '{key}'.\")\n",
    "\n",
    "        # Copy DataFrame to avoid modifying the original\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Apply VADER sentiment analysis\n",
    "        df_copy['compound'] = df_copy[text_column].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "        df_copy['positive'] = df_copy[text_column].apply(lambda x: sia.polarity_scores(x)['pos'])\n",
    "        df_copy['neutral'] = df_copy[text_column].apply(lambda x: sia.polarity_scores(x)['neu'])\n",
    "        df_copy['negative'] = df_copy[text_column].apply(lambda x: sia.polarity_scores(x)['neg'])\n",
    "\n",
    "        # Store the processed DataFrame\n",
    "        processed_dataframes[key] = df_copy\n",
    "    \n",
    "    return processed_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22bae16b-e9e0-49db-bb54-2c7f3f4bb1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: vader redo\\absa_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0                                       absa ? never    0.0000     0.000   \n",
      "1  absaghana want loan go write energy commission...    0.2500     0.288   \n",
      "2  absaghana jobcentergh offer fast efficient hir...    0.6249     0.338   \n",
      "3  absaghana amb price dropped swine buy keep com...    0.6892     0.265   \n",
      "4  absaghana imitating access bank method ! great...    0.6892     0.299   \n",
      "\n",
      "   neutral  negative  \n",
      "0    1.000     0.000  \n",
      "1    0.593     0.119  \n",
      "2    0.662     0.000  \n",
      "3    0.735     0.000  \n",
      "4    0.701     0.000  \n",
      "Sheet: vader redo\\access_bank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  people send give money ? moneygram made sent m...   -0.3400     0.054   \n",
      "1                    bought 21gh airtime , reflected    0.0000     0.000   \n",
      "2  reporting fraudster deceiving people job recru...   -0.4019     0.118   \n",
      "3  accessbankghana , spent close 2 hour new town ...    0.0000     0.000   \n",
      "4            accessbankghana please work name change    0.3182     0.365   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.833     0.113  \n",
      "1    1.000     0.000  \n",
      "2    0.664     0.218  \n",
      "3    1.000     0.000  \n",
      "4    0.635     0.000  \n",
      "Sheet: vader redo\\adb_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  adbghana l still received transaction receipt ...    0.3182     0.091   \n",
      "1                                            awesome    0.6249     1.000   \n",
      "2                               nothing effortless .    0.0000     0.000   \n",
      "3                                           good job    0.4404     0.744   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.909       0.0  \n",
      "1    0.000       0.0  \n",
      "2    1.000       0.0  \n",
      "3    0.256       0.0  \n",
      "Sheet: vader redo\\calbank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  calbankplc please get personal loan get office...    0.5719     0.266   \n",
      "1  calbankplc trying call customer service since ...   -0.2244     0.105   \n",
      "2  : facewithtearsofjoy : :loudlycryingface : swi...    0.0000     0.000   \n",
      "3  calbankplc consistently sending transaction tw...   -0.7845     0.000   \n",
      "4  calbankplc worst customer service ever . trust...    0.0516     0.324   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.734     0.000  \n",
      "1    0.747     0.149  \n",
      "2    1.000     0.000  \n",
      "3    0.685     0.315  \n",
      "4    0.400     0.276  \n",
      "Sheet: vader redo\\cbg_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0         tagged intentionally ignored message , vim   -0.3182     0.000   \n",
      "1  stop , needle needful .. provide ezwitch card ...   -0.2960     0.000   \n",
      "2                  money safe : facewithpeekingeye :    0.4404     0.592   \n",
      "3  cbgbankltd affect ability receive fund bank ac...    0.3182     0.247   \n",
      "4                        impressive : salutingface :    0.5106     0.767   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.635     0.365  \n",
      "1    0.784     0.216  \n",
      "2    0.408     0.000  \n",
      "3    0.753     0.000  \n",
      "4    0.233     0.000  \n",
      "Sheet: vader redo\\ecobank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  dear ecobankghanaplc service mile 7 branch slo...    0.3818     0.206   \n",
      "1  guy need fix customer care service . connectin...    0.6124     0.175   \n",
      "2  headoffice branch load teller booth eticketing...    0.0000     0.000   \n",
      "3  ecobank , absolute mess . bad service , horrib...   -0.9298     0.052   \n",
      "4  edc . give money , telling done paying 2023 re...    0.5267     0.254   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.794     0.000  \n",
      "1    0.779     0.045  \n",
      "2    1.000     0.000  \n",
      "3    0.541     0.407  \n",
      "4    0.746     0.000  \n",
      "Sheet: vader redo\\fidelity_bank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  nice way treat platinum card member , done stu...    0.2732     0.276   \n",
      "1  people least employ sensible people answer cos...    0.4939     0.122   \n",
      "2  fidelitybankplc recharged airtime fidelity ban...    0.7003     0.264   \n",
      "3  please adum pz worker try respect queue.this m...    0.6597     0.278   \n",
      "4  giving guy one week reinstate money . closing ...    0.5848     0.227   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.553     0.171  \n",
      "1    0.878     0.000  \n",
      "2    0.736     0.000  \n",
      "3    0.722     0.000  \n",
      "4    0.693     0.081  \n",
      "Sheet: vader redo\\first_atlantic_bank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  loading wallet .. love digital platform : smil...    0.6369     0.344   \n",
      "1  thanks feedback . visit branch get one soon po...    0.4404     0.293   \n",
      "2  refreshingly different indeed best choice open...    0.6369     0.344   \n",
      "3  ihv regret joining purple family : purpleheart...   -0.4215     0.000   \n",
      "4  firstatlanticgh long take credit account inflo...   -0.5191     0.157   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.656     0.000  \n",
      "1    0.707     0.000  \n",
      "2    0.656     0.000  \n",
      "3    0.682     0.318  \n",
      "4    0.483     0.360  \n",
      "Sheet: vader redo\\gcb_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  number call issue solved apparently hotline st...    0.1280     0.403   \n",
      "1  would love appreciate integration internationa...    0.7845     0.580   \n",
      "2  continue receiving numerous sm message mainten...   -0.2247     0.131   \n",
      "3  investigating failed atm transaction 4 month ....    0.1779     0.215   \n",
      "4  excellent work thanks observing international ...    0.7650     0.569   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.388     0.209  \n",
      "1    0.420     0.000  \n",
      "2    0.686     0.183  \n",
      "3    0.644     0.142  \n",
      "4    0.431     0.000  \n",
      "Sheet: vader redo\\gtbank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  tried using gt bank master card said invalid t...    0.2732     0.139   \n",
      "1  hi gtbankghana dm closed contact make inquiry ...    0.0000     0.000   \n",
      "2  hello send direct message . called customer se...    0.3182     0.173   \n",
      "3  done application getting week . relationship o...    0.3400     0.327   \n",
      "4                              long take application    0.0000     0.000   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.861     0.000  \n",
      "1    1.000     0.000  \n",
      "2    0.827     0.000  \n",
      "3    0.494     0.179  \n",
      "4    1.000     0.000  \n",
      "Sheet: vader redo\\stanbic_bank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  everything , avoid banking stanbicbankgh . ass...   -0.2263     0.173   \n",
      "1  create account guy without physically going ba...    0.2732     0.259   \n",
      "2  fix self . take 2 hour tell someone go east le...    0.0000     0.000   \n",
      "3                     never ever invest stanbic bank    0.0000     0.000   \n",
      "4  hard trying reach call center morning . way re...   -0.0516     0.256   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.533     0.293  \n",
      "1    0.741     0.000  \n",
      "2    1.000     0.000  \n",
      "3    1.000     0.000  \n",
      "4    0.581     0.163  \n",
      "Sheet: vader redo\\standard_chartered_bank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  brother america want create personal bank acco...    0.8900     0.425   \n",
      "1  sent 4 followup multiple email concerning debi...    0.0000     0.000   \n",
      "2  love service never hear indian speaking custom...    0.6369     0.344   \n",
      "3                          banking app complicated ?    0.0000     0.000   \n",
      "4  honest customer service worst ever experienced...   -0.3804     0.246   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.575     0.000  \n",
      "1    1.000     0.000  \n",
      "2    0.656     0.000  \n",
      "3    1.000     0.000  \n",
      "4    0.439     0.316  \n",
      "Sheet: vader redo\\uba_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0                               uba bank correct pas    0.0000     0.000   \n",
      "1  uba please help account debited 3 time unknown...    0.6124     0.455   \n",
      "2  already uba account want download app use , po...    0.0772     0.157   \n",
      "3  leaving gh200k unattended saving account 6 mon...    0.4404     0.204   \n",
      "\n",
      "   neutral  negative  \n",
      "0    1.000      0.00  \n",
      "1    0.545      0.00  \n",
      "2    0.843      0.00  \n",
      "3    0.706      0.09  \n",
      "Sheet: vader redo\\zenith_bank_sentiments\n",
      "                                        cleaned_post  compound  positive  \\\n",
      "0  please fix 24hr zenith direct call center . 3h...    0.3939     0.143   \n",
      "1    need fund interested banking .. poor service ..   -0.1027     0.229   \n",
      "2  hello , abelemkpe atm debited amount account w...   -0.2411     0.000   \n",
      "3  sent money via sent money via zenithbankghapp ...    0.0258     0.046   \n",
      "4             simple instant transfer hour reflected    0.0000     0.000   \n",
      "\n",
      "   neutral  negative  \n",
      "0    0.857     0.000  \n",
      "1    0.508     0.263  \n",
      "2    0.836     0.164  \n",
      "3    0.954     0.000  \n",
      "4    1.000     0.000  \n"
     ]
    }
   ],
   "source": [
    "# Run VADER sentiment analysis on the 'cleaned_post' column\n",
    "vader_results = vader_sentiment_analysis(processed_dfs, 'cleaned_post')\n",
    "\n",
    "# Access results\n",
    "for sheet_name, df in vader_results.items():\n",
    "    print(f\"Sheet: {sheet_name}\")\n",
    "    print(df[['cleaned_post', 'compound', 'positive', 'neutral', 'negative']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c776618d-f850-43cc-9827-27eaea842102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for vader redo\\absa_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_absa_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\access_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_access_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\adb_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_adb_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\calbank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_calbank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\cbg_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_cbg_sentiments_sentiment_results.xlsx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\creating_an_environment\\Lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for vader redo\\ecobank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_ecobank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\fidelity_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_fidelity_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\first_atlantic_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_first_atlantic_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\gcb_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_gcb_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\gtbank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_gtbank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\stanbic_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_stanbic_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\standard_chartered_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_standard_chartered_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\uba_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_uba_sentiments_sentiment_results.xlsx.\n",
      "Results for vader redo\\zenith_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/vader redo/redo sentiment results\\vader redo_zenith_bank_sentiments_sentiment_results.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Folder path where you want to save the files\n",
    "output_folder = \"File path\"  # Replace with the actual path\n",
    "\n",
    "# Ensure the folder exists, create it if it doesn't\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define a function to sanitize sheet names and file names\n",
    "def sanitize_name(name):\n",
    "    # Replace invalid characters with an underscore or remove them\n",
    "    sanitized_name = re.sub(r'[\\\\/:*?\"<>|]', '_', name)\n",
    "    return sanitized_name\n",
    "\n",
    "# Loop through each DataFrame in the vader_results dictionary\n",
    "for sheet_name, df in vader_results.items():\n",
    "    # Sanitize the sheet name to remove invalid characters\n",
    "    sanitized_sheet_name = sanitize_name(sheet_name)\n",
    "    \n",
    "    # Construct the file path for each DataFrame (using sanitized sheet name)\n",
    "    output_file_path = os.path.join(output_folder, f\"{sanitized_sheet_name}_sentiment_results.xlsx\")\n",
    "\n",
    "    # Save the DataFrame to Excel with the sanitized sheet name\n",
    "    df.to_excel(output_file_path, index=False, sheet_name=sanitized_sheet_name)\n",
    "\n",
    "    print(f\"Results for {sheet_name} have been saved to {output_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "602d2214-f9af-4be5-8396-895664491df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk>=3.8->textblob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\creating_an_environment\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   - ------------------------------------- 20.5/626.3 kB 682.7 kB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 163.8/626.3 kB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 573.4/626.3 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 626.3/626.3 kB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1ade5bd-2999-4a65-a219-4b218a5cf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis(dataframes, text_column):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on the specified column of multiple DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "        dataframes (dict): A dictionary of DataFrames.\n",
    "        text_column (str): The name of the column containing cleaned text.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of DataFrames with additional columns for sentiment polarity and subjectivity.\n",
    "    \"\"\"\n",
    "    processed_dataframes = {}\n",
    "\n",
    "    for key, df in dataframes.items():\n",
    "        # Ensure the column exists\n",
    "        if text_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{text_column}' not found in DataFrame '{key}'.\")\n",
    "        \n",
    "        # Copy DataFrame to avoid modifying the original\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Apply TextBlob sentiment analysis\n",
    "        df_copy['polarity'] = df_copy[text_column].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "        df_copy['subjectivity'] = df_copy[text_column].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "\n",
    "        # Store the processed DataFrame\n",
    "        processed_dataframes[key] = df_copy\n",
    "    \n",
    "    return processed_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2576b98e-9b33-46fa-a54e-6626c8f09a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: sentiments\\absa_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0                                         absa never      0.00         0.000\n",
      "1  want loan go write energy commission cert pay ...      0.00         0.000\n",
      "2  jobcentergh offer fast efficient hiring soluti...      0.30         0.750\n",
      "3  amb price dropped swine buy keep coming great ...      0.80         0.750\n",
      "4  imitating access bank method great least give ...      0.25         0.575\n",
      "Sheet: sentiments\\access_bank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  people send give money made sent money account...  0.000000      0.000000\n",
      "1                bought 21gh airtime hasnt reflected  0.000000      0.000000\n",
      "2  reporting fraudster deceiving people job recru...  0.600000      0.900000\n",
      "3  ive spent close 2 hour new town branch withdra...  0.018182      0.277273\n",
      "4                            please work name change  0.000000      0.000000\n",
      "Sheet: sentiments\\adb_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  l still received transaction receipt foreign t...    -0.125         0.125\n",
      "1                                            awesome     1.000         1.000\n",
      "2                                 nothing effortless     0.000         0.000\n",
      "3                                           good job     0.700         0.600\n",
      "Sheet: sentiments\\calbank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  please get personal loan get office trying sec...  0.133333      0.400000\n",
      "1  ive trying call customer service since last ni...  0.000000      0.066667\n",
      "2                                     switch calbank  0.000000      0.000000\n",
      "3  consistently sending transaction twice sending... -0.262500      0.687500\n",
      "4  worst customer service ever trust close end mo... -1.000000      1.000000\n",
      "Sheet: sentiments\\cbg_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0            tagged intentionally ignored messagevim       0.0           0.0\n",
      "1  stop needle needful provide ezwitch card acros...       0.0           0.0\n",
      "2                                         money safe       0.5           0.5\n",
      "3    affect ability receive fund bank account abroad       0.0           0.0\n",
      "4                                         impressive       1.0           1.0\n",
      "Sheet: sentiments\\ecobank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  dear service mile 7 branch slow 2hrs cant get ... -0.300000      0.400000\n",
      "1  guy need fix customer care service connecting ... -0.181548      0.377976\n",
      "2  headoffice branch load teller booth eticketing...  0.000000      0.000000\n",
      "3  ecobank absolute mess bad service horrible res... -0.353571      0.572619\n",
      "4  edc wont give money youre telling youre done p...  0.250000      0.650000\n",
      "Sheet: sentiments\\fidelity_bank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  thats nice way treat platinum card member im d...      -0.1          1.00\n",
      "1  people least employ sensible people answer cos...      -0.3          0.40\n",
      "2  recharged airtime fidelity bank phone number d...       0.3          0.45\n",
      "3  please adum pz worker try respect queuethis mo...       0.0          0.00\n",
      "4  giving guy one week reinstate money closing ac...       0.0          0.25\n",
      "Sheet: sentiments\\first_atlantic_bank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0              loading walleti love digital platform      0.25          0.30\n",
      "1          thanks feedback visit branch get one asap      0.20          0.20\n",
      "2  refreshingly different indeed best choice open...      0.50          0.45\n",
      "3                   ihv regret joining purple family      0.00          0.00\n",
      "4  long take credit account inflow 6 day delay un...     -0.05          0.40\n",
      "Sheet: sentiments\\gcb_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  number call issue solved apparently hotline st...      0.05          0.35\n",
      "1  would love appreciate integration internationa...      0.50          0.60\n",
      "2  continue receiving numerous sm message mainten...      0.04          0.52\n",
      "3  youve investigating failed atm transaction 4 m...     -0.25          0.15\n",
      "4  excellent work thanks observing international ...      0.40          0.40\n",
      "Sheet: sentiments\\gtbank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  tried using gt bank master card said invalid t...      0.00           0.0\n",
      "1      hi dm closed contact make inquiry many others      0.20           0.3\n",
      "2  hello cant send direct message called customer...      0.10           0.4\n",
      "3  done application getting week relationship off...     -0.70           0.9\n",
      "4                              long take application     -0.05           0.4\n",
      "Sheet: sentiments\\stanbic_bank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  everything avoid banking wont assist youve cha...  0.000000      0.000000\n",
      "1   create account guy without physically going bank  0.000000      0.142857\n",
      "2  fix self take 2 hour tell someone go east lego...  0.000000      0.000000\n",
      "3                     never ever invest stanbic bank  0.000000      0.000000\n",
      "4    hard trying reach call center morning way reach -0.195833      0.320833\n",
      "Sheet: sentiments\\standard_chartered_bank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  brother america want create personal bank acco...      0.15          0.55\n",
      "1  ive sent 4 followup multiple email concerning ...      0.00          0.00\n",
      "2  love service cant never hear indian speaking c...      0.50          0.60\n",
      "3                            banking app complicated     -0.50          1.00\n",
      "4  honest customer service worst ive ever experie...      0.26          0.78\n",
      "Sheet: sentiments\\uba_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0                               uba bank correct pas       0.0           0.0\n",
      "1  uba please help account debited 3 time unknown...      -0.1           0.6\n",
      "2  already uba account want download app use poss...       0.0           1.0\n",
      "3  leaving gh200k unattended saving account 6 mon...      -0.7           0.8\n",
      "Sheet: sentiments\\zenith_bank_sentiments\n",
      "                                        cleaned_post  polarity  subjectivity\n",
      "0  please fix 24hr zenith direct call center 3hrs...     0.000      0.375000\n",
      "1     need fund wont interested banking poor service    -0.075      0.550000\n",
      "2  hello abelemkpe atm debited amount account wit...     0.000      0.000000\n",
      "3  sent money via sent money via week ago deducti...    -0.250      0.321429\n",
      "4       simple instant transfer hour hasnt reflected     0.000      0.511905\n"
     ]
    }
   ],
   "source": [
    "# Run sentiment analysis on the 'cleaned_post' column\n",
    "sentiment_results = sentiment_analysis(processed_dfs, 'cleaned_post')\n",
    "\n",
    "# Access results\n",
    "for sheet_name, df in sentiment_results.items():\n",
    "    print(f\"Sheet: {sheet_name}\")\n",
    "    print(df[['cleaned_post', 'polarity', 'subjectivity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "986a4dce-e248-4a94-a82d-7aaa6bb7534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for sentiments\\absa_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_absa_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\access_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_access_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\adb_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_adb_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\calbank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_calbank_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\cbg_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_cbg_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\ecobank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_ecobank_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\fidelity_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_fidelity_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\first_atlantic_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_first_atlantic_bank_sentiments_sentiment_results.xlsx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\creating_an_environment\\Lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for sentiments\\gcb_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_gcb_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\gtbank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_gtbank_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\stanbic_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_stanbic_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\standard_chartered_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_standard_chartered_bank_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\uba_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_uba_sentiments_sentiment_results.xlsx.\n",
      "Results for sentiments\\zenith_bank_sentiments have been saved to C:/Users/User/Desktop/stanbic/competitor analysis/sentiments/text blob analysed sentiments\\sentiments_zenith_bank_sentiments_sentiment_results.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Folder path where you want to save the files\n",
    "output_folder = \"File path\"  # Replace with the actual path\n",
    "\n",
    "# Ensure the folder exists, create it if it doesn't\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define a function to sanitize sheet names and file names\n",
    "def sanitize_name(name):\n",
    "    # Replace invalid characters with an underscore or remove them\n",
    "    sanitized_name = re.sub(r'[\\\\/:*?\"<>|]', '_', name)\n",
    "    return sanitized_name\n",
    "\n",
    "# Loop through each DataFrame in the vader_results dictionary\n",
    "for sheet_name, df in sentiment_results.items():\n",
    "    # Sanitize the sheet name to remove invalid characters\n",
    "    sanitized_sheet_name = sanitize_name(sheet_name)\n",
    "    \n",
    "    # Construct the file path for each DataFrame (using sanitized sheet name)\n",
    "    output_file_path = os.path.join(output_folder, f\"{sanitized_sheet_name}_sentiment_results.xlsx\")\n",
    "\n",
    "    # Save the DataFrame to Excel with the sanitized sheet name\n",
    "    df.to_excel(output_file_path, index=False, sheet_name=sanitized_sheet_name)\n",
    "\n",
    "    print(f\"Results for {sheet_name} have been saved to {output_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb12d71-f966-4e67-9d08-e548e0eb2aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
